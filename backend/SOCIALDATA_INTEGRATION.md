# SocialData.tools Integration Guide

## Overview
This document explains how we integrated SocialData.tools for Twitter scraping while keeping Apify for Instagram and LinkedIn.

## What Changed

### Architecture
- **Twitter**: Now uses SocialData.tools API (more reliable, official API access)
  - Fetches user profile (bio, followers, verification)
  - Fetches up to 5 recent tweets for better persona accuracy
- **Instagram**: Still uses Apify (`apify/instagram-profile-scraper`)
- **LinkedIn**: Still uses Apify (`curious_coder/linkedin-profile-scraper`)

### Why SocialData.tools for Twitter?
1. **More Reliable**: Official API access, not web scraping
2. **Faster**: Direct API calls vs browser automation
3. **Better Data**: Structured JSON responses with verified fields
4. **Real Tweets**: Access to actual tweet content, not just profile synthesis
5. **Cost Effective**: Pay-per-request pricing, no browser overhead

## Setup Instructions

### 1. Get Your API Key
1. Go to [SocialData.tools](https://socialdata.tools)
2. Sign up for an account
3. Get your API key from the dashboard
4. Add credits to your account (pay-as-you-go)

### 2. Configure Environment Variables
Add your SocialData API key to `.env.local`:

```bash
SOCIALDATA_API_KEY=your_api_key_here
```

### 3. Install Dependencies
Make sure you have the updated requirements:

```bash
cd backend
pip install -r requirements.txt
```

The new `requests` package is required for API calls.

## Code Changes

### New Service: `SocialDataService`
Located in `services.py`, this class handles all Twitter API calls:

- `get_user_profile(username)`: Fetches Twitter profile by username
- `get_user_tweets(username, count=5)`: Fetches user's recent tweets (up to 5)
- `format_profile_for_profiler(profile)`: Converts profile to tweet-like format
- `_normalize_tweets(tweets)`: Normalizes tweet data for consistent formatting

### Updated: `MultiPlatformScraperService`
The `scrape_twitter()` method now:
1. Checks for hardcoded fallback data (for testing)
2. Fetches user profile via SocialData.tools API
3. **NEW**: Fetches up to 5 recent tweets for richer persona data
4. Combines profile info + real tweets into unified dataset
5. Falls back to mock data if API fails

### Data Flow
```
Username ‚Üí Profile API ‚Üí Profile Info (3 items)
       ‚Üì
Username ‚Üí Tweets API ‚Üí Recent Tweets (up to 5 items)
       ‚Üì
Combined ‚Üí [Profile Summary, Stats, Account Info, Tweet 1-5] ‚Üí Profiler
```

### Backward Compatibility
The integration maintains full backward compatibility:
- Output format matches existing expectations (list of tweet-like dicts)
- Profiler and aggregation code work without changes
- Fallback data still works for testing

## API Response Format

### SocialData.tools User Profile Response
```json
{
    "id": 44196397,
    "id_str": "44196397",
    "name": "Elon Musk",
    "screen_name": "elonmusk",
    "location": "ùïè",
    "description": "",
    "protected": false,
    "verified": true,
    "followers_count": 166213974,
    "friends_count": 506,
    "listed_count": 149577,
    "favourites_count": 37987,
    "statuses_count": 34934,
    "created_at": "2009-06-02T20:12:29.000000Z",
    "profile_banner_url": "https://...",
    "profile_image_url_https": "https://...",
    "can_dm": false
}
```

### Converted Format (for compatibility)
```python
[
    # Profile summary (3 items)
    {
        "text": "Elon Musk (@elonmusk) ‚úì Verified\nBio: ...",
        "likeCount": 0,
        "retweetCount": 0
    },
    {
        "text": "Social Stats: 166,213,974 followers, 506 following, 34,934 tweets posted",
        "likeCount": 0,
        "retweetCount": 0
    },
    {
        "text": "Account created: 2009-06-02. Listed in 149,577 lists.",
        "likeCount": 0,
        "retweetCount": 0
    },
    # Real tweets (up to 5 items)
    {
        "text": "The algorithm is the problem. We're fixing it.",
        "likeCount": 50000,
        "retweetCount": 12000
    },
    {
        "text": "Mars is looking good. Starship test soon.",
        "likeCount": 180000,
        "retweetCount": 35000
    },
    # ... up to 3 more real tweets
]
```

**Note**: If the tweet timeline endpoint is not available (404), the system gracefully continues with just the profile data. This is expected behavior as SocialData.tools may have limited endpoints.

## Testing

### Test Without API Key
The code gracefully falls back to mock data:

```python
# No SOCIALDATA_API_KEY in environment
result = scraper_service.scrape_twitter("elonmusk")
# Returns: [{"text": "Mock tweet from @elonmusk...", "likeCount": 100}]
```

### Test With API Key
```python
# SOCIALDATA_API_KEY is set
result = scraper_service.scrape_twitter("elonmusk")
# Returns: Profile data (3 items) + real tweets (up to 5 items)
# Example output: 8 total items (3 profile + 5 tweets)
```

**Expected console output:**
```
[Twitter] Scraping @elonmusk via SocialData.tools...
[SocialData] Fetching profile for @elonmusk...
[SocialData] Successfully fetched profile for @elonmusk
[SocialData] Fetching up to 5 recent tweets for @elonmusk...
[Twitter] Successfully fetched 5 real tweets for @elonmusk
[Twitter] Total data for @elonmusk: 8 items (profile + tweets)
```

**If tweet endpoint is unavailable:**
```
[Twitter] Scraping @elonmusk via SocialData.tools...
[SocialData] Fetching profile for @elonmusk...
[SocialData] Successfully fetched profile for @elonmusk
[SocialData] Fetching up to 5 recent tweets for @elonmusk...
[SocialData] Tweet timeline endpoint not available for @elonmusk (404)
[SocialData] This is normal - SocialData may not support user timelines yet
[Twitter] No real tweets available, using profile data only
[Twitter] Total data for @elonmusk: 3 items (profile + tweets)
```

### Test Fallback Data
Hardcoded fallbacks still work for testing:

```python
result = scraper_service.scrape_twitter("elonmusk")  # Uses hardcoded data
result = scraper_service.scrape_twitter("finkd")     # Uses hardcoded data
```

## Error Handling

The integration handles common errors gracefully:

1. **No API Key**: Falls back to mock data
2. **User Not Found (404)**: Returns empty list
3. **Insufficient Credits (402)**: Returns empty list, logs error
4. **Network Errors**: Returns empty list with error log
5. **API Errors**: Returns empty list with error log

All errors are logged to console for debugging.

## Cost Estimation

### SocialData.tools Pricing
- **User Profile**: ~$0.001 per request
- Much cheaper than Apify's Twitter scrapers
- No browser overhead or maintenance costs

### Comparison with Apify
- **Old (Apify)**: $0.30/1K tweets, browser-based, slower
- **New (SocialData.tools)**: $0.001/profile, API-based, faster

## Future Enhancements

Potential improvements for the future:

1. **Tweet Fetching**: Add endpoint to get actual tweets (not just profile)
   - Endpoint: `GET /twitter/tweets/{username}`
   - More detailed content analysis

2. **Rate Limiting**: Add local rate limit tracking
   - Avoid hitting API limits
   - Queue requests during high traffic

3. **Caching**: Cache profile data temporarily
   - Reduce API costs
   - Improve response times

4. **Webhook Support**: Real-time updates when profiles change
   - Monitor fighters continuously
   - Update personas automatically

## Support

### SocialData.tools Documentation
- API Reference: https://docs.socialdata.tools/reference/get-user-profile/
- Support: Check their documentation for rate limits and pricing

### Internal Code
- Main service: `backend/services.py` (lines 11-146)
- Integration point: `scrape_twitter()` method (lines 225-252)
- Platform router: `backend/platform_router.py` (unchanged)

## Troubleshooting

### Issue: "No SOCIALDATA_API_KEY" warning
**Solution**: Add your API key to `.env.local`

### Issue: "Insufficient credits" error
**Solution**: Add credits to your SocialData.tools account

### Issue: "User not found" for valid username
**Solution**: Check username format (no @ symbol) and try again

### Issue: Empty profile data returned
**Solution**: Check API logs, verify username exists on Twitter/X

## Summary

The integration successfully:
- ‚úÖ Replaced Apify Twitter scraper with SocialData.tools
- ‚úÖ Kept Apify for Instagram and LinkedIn
- ‚úÖ Maintained backward compatibility
- ‚úÖ Added proper error handling and fallbacks
- ‚úÖ Documented all changes clearly

The system is now more reliable and cost-effective for Twitter data scraping!

